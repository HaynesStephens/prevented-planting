{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/fxnCXGwU7DNWBp+9Yrq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaynesStephens/prevented-planting/blob/main/pp_model_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "-DGXRKjqRv0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lQPpcKjvJjch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installs\n",
        "%%capture\n",
        "# !pip install treeinterpreter\n",
        "# !pip install -U kaleido\n",
        "!pip install scikit-lego==0.6.14\n",
        "!pip install scikit-learn==1.2.1\n",
        "!pip install scikit-learn-intelex==2023.1.1\n",
        "!pip install ipython-autotime\n",
        "# !pip install daal4py\n",
        "# import daal4py\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "vG4HsYU3CVah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install shap"
      ],
      "metadata": {
        "id": "eBYjj0z93e-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "#intel patch to accelerate ml algorithms\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import sklearn\n",
        "print('SKLEARN', sklearn.__version__)\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "import sklego\n",
        "print('SKLEGO', sklego.__version__)\n",
        "from sklego.meta import ZeroInflatedRegressor\n",
        "import os\n",
        "import glob\n",
        "# import shap\n",
        "# print('SHAP', shap.__version__)\n",
        "\n",
        "def saveFig(fig_name, png=True):\n",
        "    if png:\n",
        "        plt.savefig(figdir+fig_name+'.png', dpi = 600, bbox_inches = 'tight', pad_inches = 0.05 )\n",
        "    else:\n",
        "        plt.savefig(figdir+fig_name+'.pdf', bbox_inches = 'tight', pad_inches = 0.05 )"
      ],
      "metadata": {
        "id": "-Df-81rTCXTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install geopandas\n",
        "!pip install mapclassify\n",
        "import geopandas as gpd"
      ],
      "metadata": {
        "id": "PRgNBUa_1kEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_fips = gpd.read_file('https://raw.githubusercontent.com/holtzy/The-Python-Graph-Gallery/master/static/data/US-counties.geojson').rename(columns={'id':'fips'})\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable"
      ],
      "metadata": {
        "id": "hj-YqxGfI6BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "mzwveqOWC5Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(modeltype, filename):\n",
        "  with open('/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/model.pkl'.format(modeltype, filename),'rb') as f:\n",
        "    rf = pickle.load(f)\n",
        "    return rf"
      ],
      "metadata": {
        "id": "AmTygJ3I4LJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZIRpart:\n",
        "    def __init__(self, rfclass, rfregr):\n",
        "        def load_model(modeltype, filename):\n",
        "            with open('/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/model.pkl'.format(modeltype, filename),'rb') as f:\n",
        "                rf = pickle.load(f)\n",
        "            return rf\n",
        "        self.classifier_ = load_model('RFclass', rfclass)\n",
        "        self.regressor_ = load_model('RFregr', rfregr)\n",
        "\n",
        "    def getOutput(self, feature_list):\n",
        "        output = pd.read_csv('/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Data/Processed/traindata-corn-excessmoist.csv')\n",
        "        output['fips'] = output.fips.astype(str).str.zfill(5)\n",
        "        output.loc[output[\"ppfrac\"] > 1.0, \"ppfrac\"] = 1.0\n",
        "        state_exc_100lon = ['HI','AK','WA','OR','CA','ID','NV','AZ','MT','WY','UT','CO','NM','AS', 'MP', 'PR', 'DC', 'GU','VI']\n",
        "        output = output[~output.state.isin(state_exc_100lon)]\n",
        "\n",
        "        # Create tempairanom\n",
        "        tempaircols = [col for col in output.columns if col.startswith('tempair_')]\n",
        "        tempairmean = output.groupby('fips')[tempaircols].mean().reset_index().rename(columns=dict(zip(tempaircols, ['tempairmean_'+f.split('_')[1] for f in tempaircols])))\n",
        "        output = output.merge(tempairmean, on='fips')\n",
        "        for i in range(1,13):\n",
        "            month = str(i).zfill(2)\n",
        "            output['tempairanom_'+month] = output['tempair_'+month] - output['tempairmean_'+month]\n",
        "\n",
        "        output['pred_cl'] = self.classifier_.predict(output[feature_list].values)\n",
        "        output['pred_re'] = self.regressor_.predict(output[feature_list].values)\n",
        "        output['pred'] = output.pred_cl * output.pred_re\n",
        "        output['pred_tot'] = output.pred * output.Total\n",
        "        return output"
      ],
      "metadata": {
        "id": "DQg8q54gaG_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modeltype = 'ZIR'\n",
        "# filename = \"ZIR-2023-08-25-16-15-12\"\n",
        "# figdir = '/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/'.format(modeltype, filename)\n",
        "# print(figdir)\n",
        "# model = load_model(modeltype, filename)\n",
        "\n",
        "# feature_list = pickle.load(open(\n",
        "#     '/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/feature_list.pkl'.format(modeltype, filename),\n",
        "#     'rb'\n",
        "# ))\n",
        "# feature_list\n",
        "\n",
        "# output = pd.read_csv(\n",
        "#     '/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/predictions-fldas.csv'.format(modeltype, filename)\n",
        "# )\n",
        "# output['fips'] = output.fips.astype(str).str.zfill(5)\n",
        "# output['pred_tot'] = output.pred * output.Total\n",
        "# output.tail()"
      ],
      "metadata": {
        "id": "_90mVgGkC6TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeltype = 'ZIRpart'\n",
        "filename = \"ZIRpart_cornsoy_PPreq\"\n",
        "figdir = '/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/'.format(modeltype, filename)\n",
        "print(figdir)\n",
        "\n",
        "# Split data into labels & features -- and convert to numpy arrays\n",
        "# CUSTOM VARIABLES\n",
        "months_incl = np.array([1,2,3,4,5,6])\n",
        "months_excl = np.array([month for month in np.arange(1,13) if month not in months_incl])\n",
        "weather_vars = ['rain_','tempair_','watersoil_'] #['evaptrans_','runsurf_','runsub_','rain_','tempair_','watersoil_','tempsoil_']\n",
        "weather_vars = [var+str(month).zfill(2) for var in weather_vars for month in months_incl]\n",
        "cst_vars = [\n",
        "    'frac_tile_drained',\n",
        "    'lat', 'lon', #'fips',\n",
        "    # 'aquifer_glacial', 'aquifer_uncon', 'aquifer_semicon',\n",
        "    # 'aquifer_glacial_pct', 'aquifer_uncon_pct', 'aquifer_semicon_pct',\n",
        "    'drain_class',\n",
        "    'awc_mean',#'awc_mean_0_5', 'awc_mean_5_15', 'awc_mean_15_30', 'awc_mean_30_60', 'awc_mean_60_100',\n",
        "    'om_mean',#'om_mean_0_5', 'om_mean_5_15', 'om_mean_15_30', 'om_mean_30_60', 'om_mean_60_100',\n",
        "    'clay_mean',#'clay_mean_0_5', 'clay_mean_5_15', 'clay_mean_15_30', 'clay_mean_30_60', 'clay_mean_60_100',\n",
        "    'ksat_mean',#'ksat_mean_0_5', 'ksat_mean_5_15', 'ksat_mean_15_30', 'ksat_mean_30_60', 'ksat_mean_60_100',\n",
        "    ]\n",
        "feature_list = cst_vars+weather_vars\n",
        "print(feature_list)"
      ],
      "metadata": {
        "id": "_AS4Ar6gdYIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ZIRpart('RFclass-2023-10-04-11-25', 'RFregr-2023-10-04-11-31')"
      ],
      "metadata": {
        "id": "DY24PMjDg0j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Historical\n",
        "output = pd.read_csv(\n",
        "    '/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/predictions-fldas.csv'.format(modeltype, filename)\n",
        ")\n",
        "output['fips'] = output.fips.astype(str).str.zfill(5)\n",
        "output['pred_tot'] = output.pred * output.Total\n",
        "output.tail()"
      ],
      "metadata": {
        "id": "EL6mPs5GjAZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl_mean = output.pred_cl.mean()"
      ],
      "metadata": {
        "id": "8blAXux8-cUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_mean = output[output.pred>0].pred_re.mean()"
      ],
      "metadata": {
        "id": "tPBTNivo-fEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.pred.max())"
      ],
      "metadata": {
        "id": "LqE4Z4Zgt8FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(output[output.ppfrac==0]) / len(output)"
      ],
      "metadata": {
        "id": "N3o48h_a2WgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# future = pd.read_csv(\n",
        "#     '/content/drive/Shareddrives/NRT Practicum - Winter 2022/Prevented Planting/Models/{0}/{1}/MRI-ESM2-0-ssp585-predictions-FR.csv'.format(modeltype, filename)\n",
        "# )\n",
        "# future['fips'] = future.fips.astype(str).str.zfill(5)\n",
        "# future['pred_tot'] = future.pred * future.Total\n",
        "# future.tail()"
      ],
      "metadata": {
        "id": "jHHAXMOuT4lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.loc[output.ppfrac >= 0.3][['ppfrac','rain_03','rain_04','rain_05']]"
      ],
      "metadata": {
        "id": "zTrYw6pJwzr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = output[feature_list]\n",
        "features = np.array(features_df)\n",
        "labels = np.array(output.ppfrac)"
      ],
      "metadata": {
        "id": "_HhFKni1jZS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update( {'font.size': 14, 'xtick.labelsize' : 14, 'ytick.labelsize' : 14} )"
      ],
      "metadata": {
        "id": "Zyhhqf5Vvwsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "I0YyrFbZZZmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = output.ppfrac.values.flatten()\n",
        "preds = output.pred.values.flatten()\n",
        "print('Goodness of Fit (R2): {0:.2f}'.format(metrics.r2_score(labels, preds)))\n",
        "\n",
        "# Extract Gini impurity values for each tree\n",
        "gini_values = np.array([tree.tree_.impurity.mean() for tree in model.classifier_.estimators_])\n",
        "print(\"Gini impurity (tree mean): {0:.4f}\".format(gini_values.mean()))\n",
        "gini_values = np.array([tree.tree_.impurity[0] for tree in model.classifier_.estimators_])\n",
        "print(\"Gini impurity (parents): {0:.4f}\".format(gini_values.mean()))\n",
        "gini_values = np.array([tree.tree_.impurity[-1] for tree in model.classifier_.estimators_])\n",
        "print(\"Gini impurity (children): {0:.4f}\".format(gini_values.mean()))\n",
        "\n",
        "\n",
        "print('Mean Squared Error (MSE): {0:.4f}'.format(metrics.mean_squared_error(labels, preds)))\n",
        "\n",
        "determined = output.determined.values.flatten() / 2.471 # acres to hectares\n",
        "pred_tot = output.pred_tot.values.flatten() / 2.471 # acres to hectares\n",
        "toterr = np.sum(pred_tot) - np.sum(determined)\n",
        "print('Total hectare difference (ha): {0:.1e}'.format(toterr))\n",
        "print('Total hectare difference (%): {0:.1e}'.format(100 * toterr / np.sum(determined)))\n",
        "\n",
        "print('\\nMean PP:', np.round(labels.mean(),3))\n",
        "print('Mean Pred.:', np.round(preds.mean(),3))\n",
        "print('Mean PP(>0):', np.round(labels[labels>0].mean(),3))\n",
        "print('Mean Pred.(>0):', np.round(preds[preds>0].mean(),3))\n",
        "print('Max PP:', np.round(labels.max(),2))\n",
        "print('Max Pred.:', np.round(preds.max(),2))"
      ],
      "metadata": {
        "id": "QJS7M-i0Zbv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2-jIP6ekF-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification accuracy"
      ],
      "metadata": {
        "id": "88OHpt57I_8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classacc = output.copy()\n",
        "blurb = 'Classifier accuracy: {0}\\n'.format(filename)\n",
        "blurb = blurb + 'Total Acc: {0:.1f}%\\n'.format(\n",
        "    100 * ( len(classacc[(classacc.ppfrac>0) & (classacc.pred>0)]) + len(classacc[(classacc.ppfrac==0) & (classacc.pred==0)]) ) / len(classacc)\n",
        ")\n",
        "\n",
        "\n",
        "# blurb = blurb + 'True Positives: {0:.1f}%\\n'.format(100*len(classacc[(classacc.ppfrac>0) & (classacc.pred>0)])/len(classacc[(classacc.ppfrac>0)]))\n",
        "# blurb = blurb + 'False Negatives: {0:.1f}%\\n'.format(100*len(classacc[(classacc.ppfrac>0) & (classacc.pred==0)])/len(classacc[(classacc.ppfrac>0)]))\n",
        "# blurb = blurb + 'True Negatives: {0:.1f}%\\n'.format(100*len(classacc[(classacc.ppfrac==0) & (classacc.pred==0)])/len(classacc[(classacc.ppfrac==0)]))\n",
        "# blurb = blurb + 'False Positives: {0:.1f}%\\n\\n'.format(100*len(classacc[(classacc.ppfrac==0) & (classacc.pred>0)])/len(classacc[(classacc.ppfrac==0)]))\n",
        "\n",
        "blurb = blurb + 'Recall: {0:.1f}%\\n'.format(100*len(classacc[(classacc.ppfrac>0) & (classacc.pred>0)])/len(classacc[(classacc.ppfrac>0)]))\n",
        "blurb = blurb + 'Precision: {0:.1f}%\\n\\n'.format(100*len(classacc[(classacc.ppfrac>0) & (classacc.pred>0)])/len(classacc[(classacc.pred>0)]))\n",
        "\n",
        "ppthreshold = 0.01\n",
        "classacc = output[(output.ppfrac>0) & (output.ppfrac<ppthreshold)].copy()\n",
        "blurb = blurb + 'Classifier accuracy UNDER {0}:\\n'.format(ppthreshold)\n",
        "# blurb = blurb + 'True Positives: {0:.1f}%\\n'.format(100*len(classacc[(classacc.ppfrac<ppthreshold) & (classacc.pred>0)])/len(classacc[(classacc.ppfrac<ppthreshold)]))\n",
        "# blurb = blurb + 'False Negatives: {0:.1f}%\\n\\n'.format(100*len(classacc[(classacc.ppfrac<ppthreshold) & (classacc.pred==0)])/len(classacc[(classacc.ppfrac<ppthreshold)]))\n",
        "blurb = blurb + 'Total Acc: {0:.1f}%\\n'.format(\n",
        "    100 * len(classacc[(classacc.pred>0)]) / len(classacc)\n",
        ")\n",
        "for ppthreshold in [0.01,0.05,0.1,0.25,0.5]:\n",
        "    classacc = output[output.ppfrac>ppthreshold].copy()\n",
        "    blurb = blurb + 'Classifier accuracy ABOVE {0}:\\n'.format(ppthreshold)\n",
        "    blurb = blurb + 'Total Acc: {0:.1f}%\\n'.format(\n",
        "    100 * len(classacc[(classacc.pred>0)]) / len(classacc)\n",
        ")\n",
        "    # blurb = blurb + 'True Positives: {0:.1f}%\\n'.format(100*len(classacc[(classacc.ppfrac>ppthreshold) & (classacc.pred>0)])/len(classacc[(classacc.ppfrac>ppthreshold)]))\n",
        "    # blurb = blurb + 'False Negatives: {0:.1f}%\\n\\n'.format(100*len(classacc[(classacc.ppfrac>ppthreshold) & (classacc.pred==0)])/len(classacc[(classacc.ppfrac>ppthreshold)]))\n",
        "\n",
        "print(blurb)"
      ],
      "metadata": {
        "id": "0_cQWuIaJO0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(figdir+'classacc.txt','w') as f:\n",
        "    f.write(blurb)"
      ],
      "metadata": {
        "id": "z_nUit1HeztP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions vs. Labels (residuals)"
      ],
      "metadata": {
        "id": "5D7JuqjteUCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl"
      ],
      "metadata": {
        "id": "jDMLgMCEuesT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make historical predictions and plot residuals.\n",
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "\n",
        "res_nopp = output[output.ppfrac==0].copy()\n",
        "pred = res_nopp.pred.values.flatten()\n",
        "ppfrac = res_nopp.ppfrac.values.flatten()\n",
        "residuals = pred - ppfrac\n",
        "ax.scatter(pred,residuals, facecolors='none', edgecolors='k', alpha=0.25)\n",
        "\n",
        "res_nopp = output[output.ppfrac>0].copy()\n",
        "pred = res_nopp.pred.values.flatten()\n",
        "ppfrac = res_nopp.ppfrac.values.flatten()\n",
        "residuals = pred - ppfrac\n",
        "ax.scatter(pred,residuals, facecolors='none', edgecolors='blue', alpha=0.25)\n",
        "\n",
        "ax.axhline(ls='dashed',c='k')\n",
        "ax.axvline(ls='dashed', lw=0.5, c='k')\n",
        "ax.text(-0.01, -0.6, 'False negatives', rotation=90, fontsize=10, ha='right')\n",
        "ax.set(xlabel='Prediction', ylabel='Residual')"
      ],
      "metadata": {
        "id": "_zXxSQLZ11Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "X = output.ppfrac\n",
        "Y = output.pred\n",
        "ax.plot([0,1],[0,1],ls='dashed',lw=1.0,c='k')\n",
        "bins1d = np.arange(0,1.01,0.05)\n",
        "hist2d,xbins, ybins = np.histogram2d(X, Y, bins=[bins1d, bins1d])\n",
        "g = ax.pcolormesh(xbins,ybins,hist2d.T,cmap='viridis',norm=mpl.colors.LogNorm())\n",
        "plt.colorbar(g, ax=ax,label='Counts')\n",
        "ax.set(xlabel='Observations',ylabel='Predictions')\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "fJftWlZHqk83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distributions Plot\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(9,12))\n",
        "ax=axes[0]\n",
        "ax.hist(output.ppfrac, bins=np.linspace(0,1.0,100), histtype='step', color='k')\n",
        "ax.hist(output.pred, bins=np.linspace(0,1.0,100), histtype='step', color='red')\n",
        "ax.set(xlabel='Prevented fraction', ylabel='Counts', title=filename)\n",
        "sns.despine()\n",
        "\n",
        "ax=axes[1]\n",
        "ax.hist(output.ppfrac, bins=np.linspace(0,1.0,100), histtype='step', color='k')\n",
        "ax.hist(output.pred, bins=np.linspace(0,1.0,100), histtype='step', color='red')\n",
        "ax.set(xlabel='Prevented fraction', ylabel='Counts',ylim=(0,2000))\n",
        "sns.despine()\n",
        "saveFig('distribution-pp')"
      ],
      "metadata": {
        "id": "5foxSiliq4uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blurb = ''\n",
        "values = output.ppfrac.values\n",
        "blurb += 'Observations'\n",
        "blurb += '\\n==0.0: {:.2f}%'.format(100*len(values[values==0])/len(values))\n",
        "blurb += '\\n>0.01: {:.2f}%'.format(100*len(values[values>0.01])/len(values))\n",
        "blurb += '\\n>0.05: {:.2f}%'.format(100*len(values[values>0.05])/len(values))\n",
        "blurb += '\\n>0.1: {:.2f}%'.format(100*len(values[values>0.1])/len(values))\n",
        "blurb += '\\n>0.2: {:.2f}%'.format(100*len(values[values>0.2])/len(values))\n",
        "blurb += '\\n>0.5: {:.2f}%'.format(100*len(values[values>0.5])/len(values))\n",
        "\n",
        "values = output.pred.values\n",
        "blurb += '\\nPredictions'\n",
        "blurb += '\\n==0.0: {:.2f}%'.format(100*len(values[values==0])/len(values))\n",
        "blurb += '\\n>0.01: {:.2f}%'.format(100*len(values[values>0.01])/len(values))\n",
        "blurb += '\\n>0.05: {:.2f}%'.format(100*len(values[values>0.05])/len(values))\n",
        "blurb += '\\n>0.1: {:.2f}%'.format(100*len(values[values>0.1])/len(values))\n",
        "blurb += '\\n>0.2: {:.2f}%'.format(100*len(values[values>0.2])/len(values))\n",
        "blurb += '\\n>0.5: {:.2f}%'.format(100*len(values[values>0.5])/len(values))\n",
        "\n",
        "print(blurb)"
      ],
      "metadata": {
        "id": "tv4lk_qQrQvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(figdir+'distribution-pp.txt','w') as f:\n",
        "    f.write(blurb)"
      ],
      "metadata": {
        "id": "irNiWuvtfqov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total predicted acres"
      ],
      "metadata": {
        "id": "Bs_mGqlRy6xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18,9))\n",
        "plt.rcParams.update( {'font.size': 14, 'xtick.labelsize' : 14, 'ytick.labelsize' : 14,\n",
        "                      'legend.fontsize': 14, 'legend.frameon': False} )\n",
        "plotdata = output.groupby(['year'])[['determined','pred_tot']].sum().reset_index()\n",
        "X = plotdata.year\n",
        "Y0 = plotdata.determined / 2.471 # acres to hectares\n",
        "Y1 = plotdata.pred_tot / 2.471 # acres to hectares\n",
        "ax.plot(X, Y0, lw=2,c='k',marker='o', label='Observations')\n",
        "ax.plot(X, Y1, lw=2,c='red',marker='o', label='Predictions')\n",
        "ax.set(ylabel='Total prevented hectacres', xlabel='Year', title='Historical totals')\n",
        "sns.despine()\n",
        "ax.set_title(filename)\n",
        "saveFig('total-pp')"
      ],
      "metadata": {
        "id": "d-RUMIZnxqht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries of events by ppfrac"
      ],
      "metadata": {
        "id": "50v-vwCqbY9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18,9))\n",
        "mpl.rcParams.update({'font.size': 14})\n",
        "for thresh, clr in zip([(0.0,1.01)],\n",
        "                       ['black']):\n",
        "    plotdata = output[(output.ppfrac>thresh[0]) & (output.ppfrac<=thresh[1])].copy()\n",
        "    plotdata['event'] = plotdata.ppfrac.astype(bool).astype(int)\n",
        "    plotdata = plotdata.groupby(['year']).sum().reset_index()\n",
        "    x = plotdata.year\n",
        "    y = plotdata.event\n",
        "    ax.plot(x,y,marker='o',color=clr,lw=2, zorder=1, ls ='solid',\n",
        "            markerfacecolor=clr, markeredgecolor='none', markersize=8, label='Observations')\n",
        "\n",
        "    plotdata = output[(output.pred>thresh[0]) & (output.pred<=thresh[1])].copy()\n",
        "    plotdata['event'] = plotdata.pred.astype(bool).astype(int)\n",
        "    plotdata = pd.concat([plotdata,\n",
        "                          pd.DataFrame(np.array([np.arange(1996,2021), np.zeros(25)]).T,columns=['year','event']).astype(int)],\n",
        "                         axis=0)\n",
        "    plotdata = plotdata.groupby(['year']).sum().reset_index()\n",
        "    x = plotdata.year\n",
        "    y = plotdata.event\n",
        "    label = 'PP: {0}'.format(thresh)\n",
        "    if y.sum()==0: label = label + ' [no pred.]'\n",
        "    ax.plot(x,y,marker='o',color=clr,lw=2, zorder=2, ls='dashed',\n",
        "            markerfacecolor='white', markeredgecolor=clr, markersize=8, label='Predictions')\n",
        "ax.set(ylim=(-10,1200),ylabel='Prevented planting events', xlabel='Year')\n",
        "ax.legend(loc=2, frameon=False)\n",
        "sns.despine()\n",
        "ax.set_title(filename)\n",
        "saveFig('model-events')"
      ],
      "metadata": {
        "id": "biNvM1OWNdTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize=(12, 12), tight_layout=True)\n",
        "# gs = fig.add_gridspec(ncols=1, nrows=5)\n",
        "\n",
        "# mpl.rcParams.update({'font.size': 20})\n",
        "# for row in range(5):\n",
        "#     ax = fig.add_subplot(gs[row,0])\n",
        "#     thresh, clr = list(zip([(0,0.01),(0.01,0.05),(0.05,0.1),(0.1,0.25),(0.25,0.5)],#,(0.5,1.01)],\n",
        "#                       ['#fed976','#feb24c','#fd8d3c','#fc4e2a','#e31a1c','#b10026']))[row]\n",
        "#     plotdata = output[(output.ppfrac>thresh[0]) & (output.ppfrac<=thresh[1])].copy()\n",
        "#     plotdata['event'] = plotdata.ppfrac.astype(bool).astype(int)\n",
        "#     plotdata = plotdata.groupby(['year']).sum().reset_index()\n",
        "#     x = plotdata.year\n",
        "#     y = plotdata.event\n",
        "#     ax.plot(x,y,marker='o',color=clr,lw=2, zorder=1, ls ='solid',\n",
        "#             markerfacecolor=clr, markeredgecolor='none', markersize=8)\n",
        "\n",
        "#     plotdata = output[(output.pred>thresh[0]) & (output.pred<=thresh[1])].copy()\n",
        "#     plotdata['event'] = plotdata.pred.astype(bool).astype(int)\n",
        "#     plotdata = pd.concat([plotdata,\n",
        "#                           pd.DataFrame(np.array([np.arange(1996,2021), np.zeros(25)]).T,columns=['year','event']).astype(int)],\n",
        "#                          axis=0)\n",
        "#     plotdata = plotdata.groupby(['year']).sum().reset_index()\n",
        "#     x = plotdata.year\n",
        "#     y = plotdata.event\n",
        "#     if y.sum()==0: label = label + ' [no pred.]'\n",
        "#     ax.plot(x,y,marker='o',color=clr,lw=2, zorder=2, ls='dashed',\n",
        "#             markerfacecolor='white', markeredgecolor=clr, markersize=8, label=label)\n",
        "#     ax.axhline(0,c='k',ls='dotted',zorder=0)\n",
        "#     if row==4: ax.set(xlabel='Year')\n",
        "#     ax.set(ylim=(-10,500), ylabel='# events\\n{0}'.format(thresh))\n",
        "# sns.despine()"
      ],
      "metadata": {
        "id": "vSQ7_XpUM1XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alt. (now above threshold)"
      ],
      "metadata": {
        "id": "Hh2sNSD2Nl7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18,9))\n",
        "mpl.rcParams.update({'font.size': 20})\n",
        "for thresh, clr in zip([0,0.01,0.05,0.1,0.25,0.5],['#fed976','#feb24c','#fd8d3c','#fc4e2a','#e31a1c','#b10026']):\n",
        "    plotdata = output[output.ppfrac>thresh].copy()\n",
        "    plotdata['event'] = plotdata.ppfrac.astype(bool).astype(int)\n",
        "    plotdata = plotdata.groupby(['year']).sum().reset_index()\n",
        "    x = plotdata.year\n",
        "    y = plotdata.event\n",
        "    ax.plot(x,y,marker='o',color=clr,lw=2, zorder=1, ls ='solid',\n",
        "            markerfacecolor=clr, markeredgecolor='none', markersize=8)\n",
        "\n",
        "    plotdata = output[output.pred>thresh].copy()\n",
        "    plotdata['event'] = plotdata.pred.astype(bool).astype(int)\n",
        "    plotdata = pd.concat([plotdata,\n",
        "                          pd.DataFrame(np.array([np.arange(1996,2021), np.zeros(25)]).T,columns=['year','event']).astype(int)],\n",
        "                         axis=0)\n",
        "    plotdata = plotdata.groupby(['year']).sum().reset_index()\n",
        "    x = plotdata.year\n",
        "    y = plotdata.event\n",
        "    label = 'Frac. Prev. >{0}'.format(thresh)\n",
        "    if y.sum()==0: label = label + ' [no pred.]'\n",
        "    ax.plot(x,y,marker='o',color=clr,lw=2, zorder=2, ls='dashed',\n",
        "            markerfacecolor='white', markeredgecolor=clr, markersize=8, label=label)\n",
        "ax.axhline(0,c='k',ls='dotted',zorder=0)\n",
        "ax.set(ylim=(-10,1200),ylabel='Prevented planting events', xlabel='Year')\n",
        "ax.legend(loc=2, frameon=False)\n",
        "sns.despine()\n",
        "ax.set_title(filename)\n",
        "saveFig('model-events-bypp')"
      ],
      "metadata": {
        "id": "vz9eWwpybbi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial Patterns"
      ],
      "metadata": {
        "id": "7aUaGbFa1QfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotReady(df, gdf, id_cols=['fips']):\n",
        "    return gdf.merge(df, on=id_cols).drop_duplicates()\n",
        "\n",
        "def mapPlot(plotdf, gdf, var='ppfrac', bins=np.arange(0,1.01,0.1), cmap='viridis'):\n",
        "    fig = plt.figure(figsize=(8,8), tight_layout=True)\n",
        "    gs = fig.add_gridspec(ncols=1, nrows=2, height_ratios=[1,0.015])\n",
        "    cmap = plt.get_cmap(cmap,bins.size-1)\n",
        "    cax = fig.add_subplot(gs[1, 0])\n",
        "\n",
        "    ax = fig.add_subplot(gs[0,0])\n",
        "    plotReady(plotdf, gdf).plot(column=var, ax=ax, edgecolor='black', linewidth=0.3,\n",
        "                                cmap=cmap, legend=True, vmin=bins.min(), vmax=bins.max(), cax=cax,\n",
        "                                legend_kwds={'orientation':'horizontal', 'ticks':bins, 'extend':'neither'})\n",
        "    ax.set_title('', fontsize=20, fontweight='bold', pad=0.04)\n",
        "    ax.axis('off')\n",
        "    cax.set_xlabel(var, rotation=0, fontsize=18)\n",
        "    cax.tick_params(labelsize=11)\n",
        "    cax.set_xticklabels(cax.get_xticklabels(), rotation=45)\n",
        "\n",
        "def tilePlot(plotdf, gdf, bins=np.arange(0,1.01,0.1), cmap='viridis'):\n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    gs = fig.add_gridspec(ncols=2, nrows=2, wspace=0.1, hspace=-0.7, width_ratios=[1,1], height_ratios=[1,0.015])\n",
        "    cmap = plt.get_cmap(cmap,bins.size-1)\n",
        "    cax = fig.add_subplot(gs[1, :])\n",
        "\n",
        "    ax = fig.add_subplot(gs[0,0])\n",
        "    plotReady(plotdf, gdf).plot(column='ppfrac', ax=ax, edgecolor='black', linewidth=0.3,\n",
        "                                cmap=cmap, legend=False, vmin=bins.min(), vmax=bins.max(), cax=cax,\n",
        "                                legend_kwds={'orientation':'horizontal', 'ticks':bins, 'extend':'neither'})\n",
        "    ax.set_title('Observations', fontsize=20, fontweight='bold', pad=0.04)\n",
        "    ax.axis('off')\n",
        "\n",
        "    ax = fig.add_subplot(gs[0,1])\n",
        "    plotReady(plotdf, gdf).plot(column='pred', ax=ax, edgecolor='black', linewidth=0.3,\n",
        "                                cmap=cmap, legend=True, vmin=bins.min(), vmax=bins.max(), cax=cax,\n",
        "                                legend_kwds={'orientation':'horizontal', 'ticks':bins, 'extend':'neither'})\n",
        "    ax.set_title(filename, fontsize=20, fontweight='bold', pad=0.04)\n",
        "    ax.axis('off')\n",
        "    cax.set_xlabel('Frac. Prevented', rotation=0, fontsize=18)\n",
        "    cax.tick_params(labelsize=15)"
      ],
      "metadata": {
        "id": "wHVPJwjT3Rvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residuals"
      ],
      "metadata": {
        "id": "6M-tiOVz6Qjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resmap = output.copy()\n",
        "resmap = resmap[resmap.ppfrac>0]\n",
        "resmap['res'] = resmap.pred - resmap.ppfrac\n",
        "resmap = resmap.groupby('fips')['res'].mean().reset_index()\n",
        "resmap.head()"
      ],
      "metadata": {
        "id": "MSitj1wr6kOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapPlot(resmap, gdf_fips, var='res', bins=np.arange(-0.1,.11,0.01), cmap='bwr')"
      ],
      "metadata": {
        "id": "34U9EFgT6SIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resmap.res.min()"
      ],
      "metadata": {
        "id": "oGdGJrxn7FYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean ppfrac"
      ],
      "metadata": {
        "id": "YDi1pKVN1SWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MEAN\n",
        "tilePlot(output.groupby('fips').mean().reset_index(), gdf_fips)\n",
        "saveFig('PPfrac-historical-mean')"
      ],
      "metadata": {
        "id": "ZV7wj5sB10FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max ppfrac"
      ],
      "metadata": {
        "id": "xorWJroO1T5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MAX\n",
        "tilePlot(output.groupby('fips').max().reset_index(), gdf_fips)\n",
        "saveFig('PPfrac-historical-max')"
      ],
      "metadata": {
        "id": "O9mCPfRX4bjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2019 ppfrac"
      ],
      "metadata": {
        "id": "bsLUvbcu1VVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2019\n",
        "tilePlot(output[output.year==2019], gdf_fips)\n",
        "saveFig('PPfrac-historical-2019')"
      ],
      "metadata": {
        "id": "fxa07Hjf4cWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importances"
      ],
      "metadata": {
        "id": "OKpj5fqT0XMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # submod = model.classifier_\n",
        "# # X = output[features_list].values\n",
        "# # y = np.round(output.ppfrac.values)\n",
        "# submod = model.regressor_\n",
        "# X = output[output.pred>0][feature_list].values\n",
        "# y = output[output.pred>0].ppfrac.values"
      ],
      "metadata": {
        "id": "DaWmKA-uNFGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.inspection import permutation_importance\n",
        "\n",
        "# result = permutation_importance(\n",
        "#     submod, X, y, n_repeats=5, random_state=4\n",
        "# )\n",
        "\n",
        "# forest_importances = pd.Series(result.importances_mean, index=feature_list)"
      ],
      "metadata": {
        "id": "1eYb9OjPGkNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots()\n",
        "# forest_importances.sort_values(ascending=False).plot.bar(yerr=result.importances_std, ax=ax)\n",
        "# ax.set_title(\"Feature importances using permutation on full model\")\n",
        "# ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "# fig.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "uYHSV2DqG-qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def impPlotQuantiles(submod, ax, title):\n",
        "    importances = submod.feature_importances_ * 100\n",
        "    quants_lo = np.quantile([tree.feature_importances_ for tree in submod.estimators_], 0.05, axis=0) * 100\n",
        "    quants_hi = np.quantile([tree.feature_importances_ for tree in submod.estimators_], 0.95, axis=0) * 100\n",
        "    forest_importances = pd.DataFrame(data={'importances':importances, 'quants_lo':quants_lo, 'quants_hi':quants_hi},\n",
        "                                      index=feature_list)\n",
        "    forest_importances = forest_importances.sort_values(by='importances',ascending=False)\n",
        "    ax.scatter(forest_importances.index, forest_importances.importances, c='k', s=16,zorder=2)\n",
        "    ax.bar(forest_importances.index, forest_importances.quants_hi - forest_importances.quants_lo,\n",
        "           bottom=forest_importances.quants_lo, width=0.75, color='orange', alpha=0.5, zorder=1)\n",
        "    ax.set_xticklabels(forest_importances.index, rotation=90)\n",
        "    cs = forest_importances.importances.cumsum().reset_index()\n",
        "    ax.axvline(cs[cs.importances>90].index[0]+0.5, ls='dashed', lw=1.0, c='k')\n",
        "    ax.set(title=title, ylabel=\"Relative importance [%]\", xlim=(-1,len(cs)+1))\n",
        "    sns.despine()\n",
        "\n",
        "def impPlotSTD(submod, ax, title):\n",
        "    importances = submod.feature_importances_ * 100\n",
        "    std = np.std([tree.feature_importances_ for tree in submod.estimators_], axis=0) * 100\n",
        "    forest_importances = pd.DataFrame(data={'importances':importances, 'variance':std}, index=feature_list)\n",
        "    forest_importances = forest_importances.sort_values(by='importances',ascending=False)\n",
        "    ax.bar(forest_importances.index, forest_importances.importances, yerr=forest_importances.variance,\n",
        "           width=0.75, color='gray', error_kw=dict(lw=0.75))\n",
        "    ax.set_xticklabels(forest_importances.index, rotation=90)\n",
        "    cs = forest_importances.importances.cumsum().reset_index()\n",
        "    ax.axvline(cs[cs.importances>90].index[0]+0.5, ls='dashed', lw=1.0, c='k')\n",
        "    ax.set(title=title, ylabel=\"Relative importance [%]\", xlim=(-1,len(cs)+1))\n",
        "    sns.despine()"
      ],
      "metadata": {
        "id": "_sxWIdWKaeWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoDbm9-Q6EAy"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2,ncols=1,figsize=(15,15))\n",
        "\n",
        "submod = model.classifier_\n",
        "ax = axes[0]\n",
        "impPlotQuantiles(submod, ax, filename+': Classifier')\n",
        "\n",
        "submod = model.regressor_\n",
        "ax = axes[1]\n",
        "impPlotQuantiles(submod, ax, filename+': Regressor')\n",
        "\n",
        "fig.tight_layout()\n",
        "saveFig('feature-importance')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partial Dependence Plots"
      ],
      "metadata": {
        "id": "Thc0VuW20jjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay, partial_dependence\n",
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "hY6CWvXg0p2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1D"
      ],
      "metadata": {
        "id": "9UWoVVI50lS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "submod = model.classifier_\n",
        "feature = 'frac_tile_drained'\n",
        "values = []\n",
        "averages = []\n",
        "nest = len(submod.estimators_)\n",
        "for i in range(nest):\n",
        "    if i % 10==0: print('{0} / {1}'.format(i, nest))\n",
        "    # results = partial_dependence(submod.estimators_[i], features=feature, X=features_df,\n",
        "    #                              percentiles=(0, 1), grid_resolution=50, kind='average')\n",
        "    results = partial_dependence(submod.estimators_[i],\n",
        "                                 features=[i for i, j in enumerate(feature_list) if j in feature],\n",
        "                                 X=features, percentiles=(0, 1), grid_resolution=20, kind='average')\n",
        "    values.append(results['values'][0].flatten())\n",
        "    averages.append(results['average'].flatten())\n",
        "values = np.array(values)\n",
        "averages = np.array(averages)"
      ],
      "metadata": {
        "id": "wQyiMRDeZjdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = values.mean(axis=0)\n",
        "avg_mean = averages.mean(axis=0)\n",
        "avg_hi = np.quantile(averages, 0.95, axis=0)\n",
        "avg_lo = np.quantile(averages, 0.05, axis=0)"
      ],
      "metadata": {
        "id": "NRmXQuTLbN-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update( {'font.size': 14, 'xtick.labelsize' : 14, 'ytick.labelsize' : 14} )"
      ],
      "metadata": {
        "id": "U5rCK-Ot5dC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axL = plt.subplots(figsize=(12, 6))\n",
        "axR = axL.twinx()\n",
        "axR.hist(features_df[feature].values.flatten(), bins=values, color='grey',\n",
        "         linewidth=0.5, edgecolor=\"white\")\n",
        "axL.plot(values, avg_mean, c='k', lw=3, zorder=5)\n",
        "axL.fill_between(values, avg_lo, avg_hi, alpha=0.5, color='#fb8072')\n",
        "axL.set_zorder(axR.get_zorder()+1)\n",
        "axL.patch.set_visible(False)\n",
        "axL.set(xlabel='Variable: ' + feature, ylabel='Effect on Prediction', title=filename+': class')\n",
        "axL.axhline(y=cl_mean, lw=0.9, ls='dashed',c='k',zorder=-1)\n",
        "axR.set(ylabel='Counts')\n",
        "sns.despine(right=False)\n",
        "saveFig('pdp-class-{0}'.format(feature))"
      ],
      "metadata": {
        "id": "qd8p7FSjzhnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.pred_re.plot.hist(bins=np.arange(0,1.005,0.005))"
      ],
      "metadata": {
        "id": "pgea7ypo9RHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.pred_re.plot.hist(bins=np.arange(0,1.005,0.005))"
      ],
      "metadata": {
        "id": "ngp0pGH39hOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "submod = model.regressor_\n",
        "feature = 'frac_tile_drained'\n",
        "values = []\n",
        "averages = []\n",
        "nest = len(submod.estimators_)\n",
        "for i in range(nest):\n",
        "    if i % 10==0: print('{0} / {1}'.format(i, nest))\n",
        "    # results = partial_dependence(submod.estimators_[i], features=feature, X=features_df,\n",
        "    #                              percentiles=(0, 1), grid_resolution=50, kind='average')\n",
        "    results = partial_dependence(submod.estimators_[i],\n",
        "                                 features=[i for i, j in enumerate(feature_list) if j in feature],\n",
        "                                 X=features, percentiles=(0, 1), grid_resolution=20, kind='average')\n",
        "    values.append(results['values'][0].flatten())\n",
        "    averages.append(results['average'].flatten())\n",
        "values = np.array(values)\n",
        "averages = np.array(averages)"
      ],
      "metadata": {
        "id": "tNWuJzVlkcWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = values.mean(axis=0)\n",
        "avg_mean = averages.mean(axis=0)\n",
        "avg_hi = np.quantile(averages, 0.95, axis=0)\n",
        "avg_lo = np.quantile(averages, 0.05, axis=0)"
      ],
      "metadata": {
        "id": "pU8od01kkcWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update( {'font.size': 14, 'xtick.labelsize' : 14, 'ytick.labelsize' : 14} )"
      ],
      "metadata": {
        "id": "CPzVSizDkcWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axL = plt.subplots(figsize=(12, 6))\n",
        "axR = axL.twinx()\n",
        "axR.hist(features_df[feature].values.flatten(), bins=values, color='grey',\n",
        "         linewidth=0.5, edgecolor=\"white\")\n",
        "axL.plot(values, avg_mean, c='k', lw=3, zorder=5)\n",
        "axL.fill_between(values, avg_lo, avg_hi, alpha=0.5, color='#fb8072')\n",
        "axL.set_zorder(axR.get_zorder()+1)\n",
        "axL.patch.set_visible(False)\n",
        "axL.set(xlabel='Variable: ' + feature, ylabel='Effect on Prediction', title=filename+': regr')\n",
        "axL.axhline(y=re_mean, lw=0.9, ls='dashed',c='k',zorder=-1)\n",
        "axR.set(ylabel='Counts')\n",
        "sns.despine(right=False)\n",
        "saveFig('pdp-regr-{0}'.format(feature))"
      ],
      "metadata": {
        "id": "WFwNFCvBkcWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Done here."
      ],
      "metadata": {
        "id": "hpbrzl-Blicz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D"
      ],
      "metadata": {
        "id": "mMoDV6db04kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update( {'font.size': 14, 'xtick.labelsize' : 14, 'ytick.labelsize' : 14} )"
      ],
      "metadata": {
        "id": "tA2utU2NSiXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "submod = model.classifier_\n",
        "feature = ['rain_04', 'rain_05']\n",
        "feat0vals = []\n",
        "feat1vals = []\n",
        "averages = []\n",
        "nest = len(submod.estimators_)\n",
        "for i in range(nest):\n",
        "    if i%10==0: print('{0} / {1}'.format(i, nest))\n",
        "    # results = partial_dependence(submod.estimators_[i], features=feature, X=features_df,\n",
        "    #                              percentiles=(0, 1), grid_resolution=50, kind='average')\n",
        "    results = partial_dependence(submod.estimators_[i],\n",
        "                                 features=[i for i, j in enumerate(feature_list) if j in feature],\n",
        "                                 X=features, percentiles=(0, 1), grid_resolution=10, kind='average')\n",
        "    feat0vals.append(results['values'][0])\n",
        "    feat1vals.append(results['values'][1])\n",
        "    averages.append(results['average'][0])\n",
        "feat0vals = np.array(feat0vals)\n",
        "feat1vals = np.array(feat1vals)\n",
        "averages = np.array(averages)"
      ],
      "metadata": {
        "id": "wVjzTRwS9O4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat0vals = feat0vals.mean(axis=0)\n",
        "feat1vals = feat1vals.mean(axis=0)\n",
        "avg_mean = averages.mean(axis=0)"
      ],
      "metadata": {
        "id": "Cbb7r2iJ-L-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "featvals2d = np.meshgrid(feat0vals, feat1vals)\n",
        "p = ax.contourf(featvals2d[0], featvals2d[1], avg_mean, levels=np.linspace(0.25,0.5,20))\n",
        "plt.colorbar(p, ax=ax, label='Effect on Prediction')\n",
        "\n",
        "X = output[output.ppfrac<0.15][feature[0]].values.flatten()\n",
        "Y = output[output.ppfrac<0.15][feature[1]].values.flatten()\n",
        "ax.scatter(X, Y, s=1, facecolors='none', edgecolors='black', alpha=0.3)\n",
        "\n",
        "X = output[output.ppfrac>=0.15][feature[0]].values.flatten()\n",
        "Y = output[output.ppfrac>=0.15][feature[1]].values.flatten()\n",
        "ax.scatter(X, Y, s=50, facecolors='none', edgecolors='red', alpha=0.4)\n",
        "\n",
        "xbins = np.linspace(feat0vals.min(), feat0vals.max(), 20)\n",
        "ybins = np.linspace(feat1vals.min(), feat1vals.max(), 20)\n",
        "H, xedges, yedges = np.histogram2d(X, Y, bins = [xbins, ybins])\n",
        "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
        "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
        "\n",
        "ax.set(xlabel='April Rain [in.]', ylabel='May Rain [in.]', title=filename+': class')\n",
        "# ax.contour(xcenters, ycenters, H.T, levels=np.linspace(3,213,20))\n",
        "saveFig('pdp2d-class-{0}-{1}'.format(feature[0], feature[1]))"
      ],
      "metadata": {
        "id": "V8MEL7F4-u0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, axL = plt.subplots(figsize=(12, 6))\n",
        "# axR = axL.twinx()\n",
        "# # axR.hist(features_df[feature].values.flatten(), bins=values, color='grey',\n",
        "# #          linewidth=0.5, edgecolor=\"white\")\n",
        "# i = 1\n",
        "# axL.plot(featvals2d[1][:,i], avg_mean[:,i], c='k', lw=3, zorder=5)\n",
        "# avg_hi = np.quantile(averages[:,:,i], 0.95, axis=0)\n",
        "# avg_lo = np.quantile(averages[:,:,i], 0.05, axis=0)\n",
        "# axL.fill_between(featvals2d[1][:,i], avg_lo, avg_hi, alpha=0.5, color='#fb8072')\n",
        "\n",
        "# i=-1\n",
        "# axL.plot(featvals2d[1][:,i], avg_mean[:,i], c='k', lw=3, zorder=5)\n",
        "# avg_hi = np.quantile(averages[:,:,i], 0.95, axis=0)\n",
        "# avg_lo = np.quantile(averages[:,:,i], 0.05, axis=0)\n",
        "# axL.fill_between(featvals2d[1][:,i], avg_lo, avg_hi, alpha=0.5, color='#fb8072')\n",
        "\n",
        "# axL.set_zorder(axR.get_zorder()+1)\n",
        "# axL.patch.set_visible(False)\n",
        "# axL.set(xlabel='Variable: {0} v {1}'.format(feature[0],feature[1]), ylabel='Effect on Prediction')\n",
        "# axR.set(ylabel='Counts')\n",
        "# sns.despine(right=False)\n",
        "# # saveFig('Regressor-PDP')"
      ],
      "metadata": {
        "id": "aaufW98E06FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mSBeFnNz08dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree interpreter"
      ],
      "metadata": {
        "id": "KKWAL80y1G8P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBTlPAejHrzw"
      },
      "outputs": [],
      "source": [
        "# from sklearn.tree import plot_tree\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(30,30)) # Resize figure\n",
        "# plot_tree(model.regressor_.estimators_[0], filled=True, ax=ax, max_depth = 2, feature_names = feature_list, fontsize = 26)\n",
        "# plt.show()\n",
        "# plt.figure(figsize=(4,2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submodel = model.classifier_"
      ],
      "metadata": {
        "id": "3lAk8jToYeXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# latvals = []\n",
        "# for N in range(submodel.n_estimators):\n",
        "#     tree_i = submodel.estimators_[N]\n",
        "#     n_nodes = tree_i.tree_.node_count\n",
        "#     children_left = tree_i.tree_.children_left\n",
        "#     children_right = tree_i.tree_.children_right\n",
        "#     feature = tree_i.tree_.feature\n",
        "#     threshold = tree_i.tree_.threshold\n",
        "#     for i in range(n_nodes):\n",
        "#         fi = feature[i]\n",
        "#         if fi == 1:\n",
        "#             # print(feature_list[1], '<=', threshold[i])\n",
        "#             latvals.append(threshold[i])\n",
        "# latvals = np.array(latvals)"
      ],
      "metadata": {
        "id": "Rqrn5juHS07J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lonvals = []\n",
        "# for N in range(submodel.n_estimators):\n",
        "#     tree_i = submodel.estimators_[N]\n",
        "#     n_nodes = tree_i.tree_.node_count\n",
        "#     children_left = tree_i.tree_.children_left\n",
        "#     children_right = tree_i.tree_.children_right\n",
        "#     feature = tree_i.tree_.feature\n",
        "#     threshold = tree_i.tree_.threshold\n",
        "#     for i in range(n_nodes):\n",
        "#         fi = feature[i]\n",
        "#         if fi == 2:\n",
        "#             # print(feature_list[2], '<=', threshold[i])\n",
        "#             lonvals.append(threshold[i])\n",
        "# lonvals = np.array(lonvals)"
      ],
      "metadata": {
        "id": "G7LKv3PLajs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.hist(latvals, bins=100)"
      ],
      "metadata": {
        "id": "ychpc83ZaCi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.hist(lonvals, bins=100)"
      ],
      "metadata": {
        "id": "5RxpTxwfa2rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def plotReady(df, gdf, id_cols=['fips']):\n",
        "#     return gdf.merge(df, on=id_cols).drop_duplicates()\n",
        "\n",
        "# def tilePlot(plotdf, gdf, ax, bins=np.arange(0,31,5), cmap='inferno'):\n",
        "#     plotReady(plotdf, gdf).plot(column='YearsPP', ax=ax, edgecolor='black', linewidth=0.3,\n",
        "#                                 cmap=cmap, legend=False, vmin=bins.min(), vmax=bins.max(),\n",
        "#                                 legend_kwds={'orientation':'horizontal', 'ticks':bins, 'extend':'neither'})\n",
        "#     # ax.axis('off')"
      ],
      "metadata": {
        "id": "PyFL5Wigd7b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numY = output.copy()\n",
        "# numY = numY[numY.ppfrac>0.0]\n",
        "# numY['YearsPP'] = 1"
      ],
      "metadata": {
        "id": "0_xS9lBDhg6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.gridspec as gridspec\n",
        "# import numpy as np\n",
        "\n",
        "# # Generate sample data for latitude and longitude\n",
        "# np.random.seed(42)\n",
        "# latitude_data = np.random.uniform(-90, 90, 1000)\n",
        "# longitude_data = np.random.uniform(-180, 180, 1000)\n",
        "\n",
        "# # Create the figure and grid specifications\n",
        "# fig = plt.figure(figsize=(9, 6))\n",
        "# gs = gridspec.GridSpec(2, 2, width_ratios=[4, 1], height_ratios=[3, 1])\n",
        "\n",
        "# # First subplot: Map with latitude and longitude axes\n",
        "# ax1 = plt.subplot(gs[0])\n",
        "# p = tilePlot(numY.groupby(\"fips\")['YearsPP'].sum().reset_index(), gdf_fips, ax1)\n",
        "# ax1.grid(True)\n",
        "# plt.gca().set_aspect('auto')\n",
        "\n",
        "# # Second subplot: Histogram of latitude values\n",
        "# ax2 = plt.subplot(gs[1], sharey=ax1)\n",
        "# ax2.hist(latvals, bins=100, orientation='horizontal', alpha=0.7)\n",
        "# ax2.grid(True)\n",
        "\n",
        "# # Third subplot: Histogram of longitude values\n",
        "# ax3 = plt.subplot(gs[2], sharex=ax1)\n",
        "# ax3.hist(lonvals, bins=100, alpha=0.7)\n",
        "# ax3.grid(True)\n",
        "\n",
        "# # Adjust the layout and add a main title\n",
        "# plt.tight_layout()\n",
        "# # Display the plot\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "QjNtWPNabrzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}